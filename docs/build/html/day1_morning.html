

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Day 1 Morning &mdash; Micro 612 genomics workshop 3.0 documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700&subset=latin,cyrillic' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Micro 612 genomics workshop 3.0 documentation" href="index.html"/>
        <link rel="next" title="Day 1 Afternoon" href="day1_afternoon.html"/>
        <link rel="prev" title="Microbial Comparative Genomics Workshop" href="index.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        
          <a href="index.html" class="fa fa-home"> Micro 612 genomics workshop</a>
        
        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="">Day 1 Morning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installing-and-setting-up-cyberduck-for-file-transfer">Installing and setting up Cyberduck for file transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#getting-your-data-onto-flux-and-setting-up-environment-variable">Getting your data onto Flux and setting up environment variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="#unix-is-your-friend">Unix is your friend</a></li>
<li class="toctree-l2"><a class="reference internal" href="#your-first-sequence-analysis-program">Your first sequence analysis program!!!</a></li>
<li class="toctree-l2"><a class="reference internal" href="#power-of-unix-commands">Power of Unix commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pairing-fastq-files-with-for-loop">Pairing fastq Files with for loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exploring-gff-files">Exploring GFF files</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plotting-genomic-coverage-in-r">Plotting genomic coverage in R</a></li>
<li class="toctree-l2"><a class="reference internal" href="#submit-variant-calling-job">Submit Variant Calling Job</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="day1_afternoon.html">Day 1 Afternoon</a><ul>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#contamination-screening-using-fastq-screen">Contamination Screening using FastQ Screen</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#quality-control-using-fastqc">Quality Control using FastQC</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#quality-trimming-using-trimmomatic">Quality Trimming using Trimmomatic</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#variant-calling-for-collistin-resistant-klebsiella-pneumoniae">Variant Calling for Collistin resistant Klebsiella pneumoniae</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#step1-cleaning">Step1_cleaning</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#step2-mapping">Step2_mapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#step3-samtobamconversion">Step3_samtobamconversion</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#step4-removeduplicates">Step4_removeduplicates</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#step5-variantcalling">Step5_variantcalling</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#step6-variantfilteraion">Step6_variantfilteraion</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#variant-annotation-using-snpeff">Variant Annotation using snpEff</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#generate-alignment-statistics">Generate Alignment Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#visualize-bam-and-vcf-files-in-igv-integrative-genome-viewer">Visualize BAM and VCF files in IGV (Integrative Genome Viewer)</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#exercise-daptomycin-resistance-in-vre">Exercise – Daptomycin resistance in VRE</a></li>
<li class="toctree-l2"><a class="reference internal" href="day1_afternoon.html#exercise-colistin-resistance-in-acinetobacter">Exercise – Colistin resistance in Acinetobacter</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="day2_morning.html">Day 2 Morning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="day2_morning.html#genome-assembly-using-spades-pipeline">Genome Assembly using Spades Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_morning.html#assembly-evaluation-using-quast">Assembly evaluation using QUAST</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_morning.html#generating-multiple-sample-reports-using-multiqc">Generating multiple sample reports using multiqc</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_morning.html#compare-assembly-to-reference-genome-and-post-assembly-genome-improvement">Compare assembly to reference genome and post-assembly genome improvement</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_morning.html#genome-annotation">Genome Annotation</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_morning.html#using-abacas-and-act-to-compare-vre-vse-genome">Using abacas and ACT to compare VRE/VSE genome</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="day2_afternoon.html">Day 2 Afternoon</a><ul>
<li class="toctree-l2"><a class="reference internal" href="day2_afternoon.html#high-throughput-blast-and-pan-genome-analysis">High-throughput BLAST and pan-genome analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_afternoon.html#determine-which-genomes-contain-kpc-genes-using-blast">Determine which genomes contain KPC genes using BLAST</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_afternoon.html#identify-antibiotic-resistance-genes-with-ariba-directly-from-paired-end-reads">Identify antibiotic resistance genes with ARIBA directly from paired end reads</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_afternoon.html#perform-pan-genome-analysis-with-roary">Perform pan-genome analysis with Roary</a></li>
<li class="toctree-l2"><a class="reference internal" href="day2_afternoon.html#perform-genome-comparisons-with-act">Perform genome comparisons with ACT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="day3_morning.html">Day 3 Morning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="day3_morning.html#perform-whole-genome-alignment-with-mauve-and-convert-alignment-to-other-useful-formats">Perform whole genome alignment with Mauve and convert alignment to other useful formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_morning.html#perform-some-dna-sequence-comparisons-and-phylogenetic-analysis-in-ape-an-r-package">Perform some DNA sequence comparisons and phylogenetic analysis in APE, an R package</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_morning.html#perform-snp-density-analysis-to-discern-evidence-of-recombination">Perform SNP density analysis to discern evidence of recombination</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_morning.html#perform-recombination-filtering-with-gubbins">Perform recombination filtering with Gubbins</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_morning.html#overlay-metadata-on-your-tree-using-r">Overlay metadata on your tree using R</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="day3_afternoon.html">Day 3 Afternoon</a><ul>
<li class="toctree-l2"><a class="reference internal" href="day3_afternoon.html#klebsiella-pneumoniae-comparative-genomic-analysis">Klebsiella pneumoniae comparative genomic analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_afternoon.html#perform-qc-on-fastq-files">Perform QC on fastq files</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_afternoon.html#examine-results-of-spandx-pipeline">Examine results of SPANDx pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_afternoon.html#recombination-detection-and-tree-generation">Recombination detection and tree generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_afternoon.html#phylogenetic-tree-annotation-and-visualization">Phylogenetic tree annotation and visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="day3_afternoon.html#assessment-of-genomic-deletions">Assessment of genomic deletions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="online_resources.html">Helpful resources for microbial genomics</a></li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Micro 612 genomics workshop</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Day 1 Morning</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="_sources/day1_morning.txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
  <div class="section" id="day-1-morning">
<span id="day-1-morning"></span><h1>Day 1 Morning<a class="headerlink" href="#day-1-morning" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="index.html">[HOME]</a></p>
<p>This morning we will learn how to set up our unix environment which is a necessity when it comes to working on command line. Setting up an environment variable will make our life easier and running commands more enjoyable. We will brush up on few unix programs that some of you learned in Data Carpentry workshop and see how they can be employed for accessing and parsing omics datasets. We will also learn how for loops and awk can be employed to parse and extract complex information from common bioinformatics file formats. At the end of the session, an R exercise will give you an overview as to how you can parse and visualize omics datasets.</p>
<div class="section" id="installing-and-setting-up-cyberduck-for-file-transfer">
<span id="installing-and-setting-up-cyberduck-for-file-transfer"></span><h2>Installing and setting up Cyberduck for file transfer<a class="headerlink" href="#installing-and-setting-up-cyberduck-for-file-transfer" title="Permalink to this headline">¶</a></h2>
<p>During workshop, we will transfer different output files from flux to your local system. Cyberduck makes it easier to drag and drop any remote file onto your local system and vice versa. Of course, you can use &#8220;scp&#8221; to transfer files but Cyberduck provides a graphical interface to manage file transfer and helps avoid typing long file paths and commands.</p>
<blockquote>
<div><strong><em>1. Go to <a class="reference external" href="https://cyberduck.io/">this</a> cyberduck website and download the executable for your respective operating system.</em></strong></div></blockquote>
<blockquote>
<div><strong><em>2. Double-click on the downloaded zip file to unzip it and double click cyberduck icon.</em></strong></div></blockquote>
<blockquote>
<div><strong><em>3. Type sftp://flux-xfer.arc-ts.umich.edu in quickconnect bar, press enter and enter your flux username and password.</em></strong></div></blockquote>
<blockquote>
<div><strong><em>4. This will take you to your flux home directory /home/username. Select &#8220;Go&#8221; from tool bar at the top then select &#8220;Go to folder&#8221; and enter workshop home directory path: /scratch/micro612w19_fluxod/</em></strong></div></blockquote>
<p>To transfer or upload a file, you can drag and drop it into the location you want.</p>
</div>
<div class="section" id="getting-your-data-onto-flux-and-setting-up-environment-variable">
<span id="getting-your-data-onto-flux-and-setting-up-environment-variable"></span><h2>Getting your data onto Flux and setting up environment variable<a class="headerlink" href="#getting-your-data-onto-flux-and-setting-up-environment-variable" title="Permalink to this headline">¶</a></h2>
<p><strong>Log in to Flux</strong></p>
<pre class="literal-block">
ssh username&#64;flux-login.arc-ts.umich.edu
</pre>
<!-- **Set up your .bashrc file so your environment is all set for genomic analysis!** --><p><strong>Setting up environment variables in .bashrc file so your environment is all set for genomic analysis!</strong></p>
<p>Environment variables are the variables/values that describe the environment in which programs run in. All the programs and scripts on your unix system use these variables for extracting information such as:</p>
<ul class="simple">
<li>What is my current working directory?,</li>
<li>Where are temporary files stored?,</li>
<li>Where are perl/python libraries?,</li>
<li>Where is Blast installed? etc.</li>
</ul>
<p>In addition to environment variables that are set up by system administators, each user can set their own environment variables to customize their experience. This may sound like something super advanced that isn&#8217;t relevant to beginners, but that&#8217;s not true!</p>
<p>Some examples of ways that we will use environment variables in the class are:</p>
<ol class="simple">
<li>create shortcuts for directories that you frequently go to,</li>
<li>tell unix where frequently used programs live, so you don&#8217;t have to put the full path name each time you use it and</li>
<li>setup a shortcut for getting on a cluster node, so that you don&#8217;t have to write out the full command each time.</li>
</ol>
<p>One way to set your environment variables would be to manually set up these variables everytime you log in, but this would be extremely tedious and inefficient. So, Unix has setup a way around this, which is to put your environment variable assignments in special files called .bashrc or .bash_profile. Every user has one or both of these files in their home directory, and what&#8217;s special about them is that the commands in them are executed every time you login. So, if you simply set your environmental variable assignments in one of these files, your environment will be setup just the way you want it each time you login!</p>
<p>All the softwares/tools that we need in this workshop are installed in a directory &#8220;/scratch/micro612w19_fluxod/shared/bin/&#8221; and we want the shell to look for these installed tools in this directory. For this, We will save the full path to these tools in an environment variable PATH.</p>
<blockquote>
<div><strong><em>i. Make a backup copy of bashrc file in case something goes wrong.</em></strong></div></blockquote>
<pre class="literal-block">

cp ~/.bashrc ~/bashrc_backup

#Note: &quot;~/&quot; represents your home directory. On flux, these means /home/username

</pre>
<blockquote>
<div><strong><em>ii. Open ~/.bashrc file using any text editor and add the following lines to your .bashrc file.</em></strong></div></blockquote>
<p><details>
<summary>Click here to expand entries</summary></p>
<pre class="literal-block">
##Micro612 Workshop ENV

#Aliases
alias iflux='qsub -I -V -l nodes=1:ppn=4,pmem=4000mb,walltime=1:00:00:00 -q fluxod -l qos=flux -A micro612w19_fluxod'
alias wd='cd /scratch/micro612w19_fluxod/username/'
alias d1m='cd /scratch/micro612w19_fluxod/username/day1_morn'
alias d1a='cd /scratch/micro612w19_fluxod/username/day1_after'
alias d2m='cd /scratch/micro612w19_fluxod/username/day2_morn'
alias d2a='cd /scratch/micro612w19_fluxod/username/day2_after'
alias d3m='cd /scratch/micro612w19_fluxod/username/day3_morn'
alias d3a='cd /scratch/micro612w19_fluxod/username/day3_after'


#Flux Modules
module load perl-modules

#Perl Libraries
export PERL5LIB=/scratch/micro612w19_fluxod/shared/bin/PAGIT/lib:/scratch/micro612w19_fluxod/shared/bin/vcftools_0.1.12b/perl:$PERL5LIB
export PERL5LIB=/scratch/micro612w19_fluxod/shared/perl_libs:$PERL5LIB

#Bioinformatics Tools
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/ncbi-blast-2.7.1+/bin/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/MultiQC/build/scripts-2.7/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/mauve_snapshot_2015-02-13/linux-x64/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/vcftools_0.1.12b/perl/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/tabix-0.2.6/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/bwa-0.7.12/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/Trimmomatic/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/bcftools-1.2/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/samtools-1.2/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/sratoolkit/bin/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/Spades/bin/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/FastQC/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/GenomeAnalysisTK-3.3-0/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/picard-tools-1.130/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/qualimap_v2.1/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/vcftools_0.1.12b/bin/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/snpEff/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/PAGIT/ABACAS/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/blast-2.2.26/bin/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/quast/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/MUMmer3.23/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/fastq_screen_v0.5.2/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/prokka-1.11/bin/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/LS-BSR-master/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/bowtie2-2.2.6/
export PATH=$PATH:/scratch/micro612w19_fluxod/shared/bin/mcl-14-137/src/alien/oxygen/src/

</pre>
<p></details></p>
<p>Note: Replace &#8220;username&#8221; under alias shortcuts with your own umich &#8220;uniqname&#8221;. In the text editor, nano, you can do this by</p>
<ul class="simple">
<li>typing Ctrl + \ and You will then be prompted to type in your search string (here, username).</li>
<li>Press return. Then you will be prompted to enter what you want to replace &#8220;username&#8221; with (here, your uniqname).</li>
<li>Press return. Then press a to replace all incidences or y to accept each incidence one by one.</li>
</ul>
<p>You can also customize the alias name such as wd, d1m etc. catering to your own need and convenience.</p>
<p>The above environment settings will set various shortcuts such as &#8220;iflux&#8221; for entering interactive flux session, &#8220;wd&#8221; to navigate to your workshop directory, call necessary flux modules and perl libraries required by certain tools and finally sets the path for bioinformatics programs that we will run during the workshop.</p>
<blockquote>
<div><strong><em>iii. Save the file and Source .bashrc file to make these changes permanent.</em></strong></div></blockquote>
<pre class="literal-block">

source ~/.bashrc

</pre>
<blockquote>
<div><strong><em>iv. Check if the $PATH environment variable is updated</em></strong></div></blockquote>
<pre class="literal-block">

echo $PATH

#You will see a long list of paths that has been added to your $PATH variable

wd

</pre>
<p>You should be in your workshop working directory that is /scratch/micro612w19_fluxod/username</p>
<!-- Check the dependencies Pending tree file system Pending--></div>
<div class="section" id="unix-is-your-friend">
<span id="unix-is-your-friend"></span><h2>Unix is your friend<a class="headerlink" href="#unix-is-your-friend" title="Permalink to this headline">¶</a></h2>
<p>Up until now you’ve probably accessed sequence data from NCBI by going to the website, laboriously clicking around and finally finding and downloading the data you want.</p>
<p>There are a lot of reasons that is not ideal:</p>
<ul class="simple">
<li>It’s frustrating and slow to deal with the web interface</li>
<li>It can be hard to keep track of where the data came from and exactly which version of a sequence you downloaded</li>
<li>Its not conducive to downloading lots of sequence data</li>
</ul>
<p>To download sequence data in Unix you can use a variety of commands (e.g. sftp, wget, curl). Here, we will use the curl command to download some genome assemblies from NCBI ftp location:</p>
<ul class="simple">
<li>Go to your class home directory (use your wd shortcut!)</li>
<li>Execute the following commands to copy files for this morning’s exercises to your home directory:</li>
</ul>
<pre class="literal-block">
cp -r /scratch/micro612w19_fluxod/shared/data/day1_morn/ ./

cd day1_morn/

#or 

d1m

ls

</pre>
<ul class="simple">
<li>Now get three genome sequences with the following commands:</li>
</ul>
<pre class="literal-block">
curl ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/bacteria/Acinetobacter_baumannii/latest_assembly_versions/GCF_000018445.1_ASM1844v1/GCF_000018445.1_ASM1844v1_genomic.fna.gz &gt; Acinetobacter_baumannii.fna.gz

curl ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/bacteria/Klebsiella_pneumoniae/latest_assembly_versions/GCF_000220485.1_ASM22048v1/GCF_000220485.1_ASM22048v1_genomic.fna.gz &gt; Klen_pneu.fna.gz

curl ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/bacteria/Escherichia_coli/all_assembly_versions/GCF_000194495.1_ASM19449v2/GCF_000194495.1_ASM19449v2_genomic.fna.gz &gt; E_coli.fna.gz

</pre>
<ul class="simple">
<li>Decompress the gzip compressed fasta file using gzip command</li>
</ul>
<pre class="literal-block">
gzip -d Acinetobacter_baumannii.fna.gz
gzip -d Klen_pneu.fna.gz 
gzip -d E_coli.fna.gz
</pre>
<p>These files are genome assemblies in fasta format. Fasta files are a common sequence data format that is composed of alternating sequence headers (sequence names and comments) and their corresponding sequences. Of great importance, the sequence header lines must start with “&gt;”. These genome assemblies have one header line for each contig in the assembly, and our goal will be to count the number of contigs/sequences. To do this we will string together two Unix commands: “grep” and “wc”. “grep” (stands for global regular expression print), is an extremely powerful pattern matching command, which we will use to identify all the lines that start with a “&gt;”. “wc” (stand for word count) is a command for counting words, characters and lines in a file. To count the number of contigs in one of your fasta files enter:</p>
<pre class="literal-block">
grep &quot;&gt;&quot; E_coli.fna | wc -l
</pre>
<p>Try this command on other assemblies to see how many contigs they contain.</p>
</div>
<div class="section" id="your-first-sequence-analysis-program">
<span id="your-first-sequence-analysis-program"></span><h2>Your first sequence analysis program!!!<a class="headerlink" href="#your-first-sequence-analysis-program" title="Permalink to this headline">¶</a></h2>
<p>OK, so now that we have a useful command, wouldn’t it be great to turn it into a program that you can easily apply to a large number of genome assemblies? Of course it would! So, now we are going to take out cool contig counting command, and put it in a shell script that applies it to all files in the desired directory.</p>
<!--- Copy “/scratch/micro612w19_fluxod/shared/fasta_counter.sh” to your current directory (Hint – use the “cp” command)--><p>There will be times when you have multiple sets of files in a folder in which case it becomes cumbersome to run individual commands on each file. To simplify this task, most programming language have a concept of loops that can be employed to repeat a task/command on a bunch of files repeatedly. Here we have three fasta files for which we want to know the number of contigs in each file. We can either run the above mentioned grep command seperately on each file or use it in a &#8220;for&#8221; loop that iterates through a set of values/files until that list is exhausted.</p>
<p>Try the below example of for loop, that loops over a bunch of numbers and prints out each value until the list is exhausted.</p>
<pre class="literal-block">
for i in 1 2 3 4 5; do echo &quot;Looping ... number $i&quot;; done
</pre>
<p>A simple for loop statement consists of three sections:</p>
<ol class="simple">
<li>for statement that loops through values and files</li>
<li>a do statement that can be any type of command that you want to run on a file or a tool that uses the current loop value  as an input</li>
<li>done statement that indicates completion of a do statement.</li>
</ol>
<p>Note that the list values - (1 2 3 4 5) in the above for loop can be anything at all. It can be a bunch of files in a folder with a specific extension (*.gz, *.fasta, *.fna) or a list of values generated through a seperate command that we will see later.</p>
<p>We will incorporate a similar type of for loop in fasta_counter.sh script that will loop over all the *.fna files in the folder. We will provide the name of the folder through a command line argument and count the number of contigs in each file. A command line argument is a sort of input that can be provided to a script which can then be used in different ways inside the script. fasta_counter.sh requires to know which directory to look for for *.fna files. For this purpose, we will use positional parameters that are a series of special variables ($0 through $9) that contain the contents of the command line.</p>
<p>Lets take an example to understand what those parameters stands for:</p>
<pre class="literal-block">
./some_program.sh Argument1 Argument2 Argument3
</pre>
<p>In the above command, we provide three command line Arguments that acts like an input to some_program.sh
These command line argument inputs can then be used to inside the scripts in the form of $0, $1, $2 and so on in different ways to run a command or a tool.</p>
<p>Try running the above command and see how it prints out each positional parameters. $0 will be always be the name of the script. $1 would contain &#8220;Argument1&#8221; , $2 would contain &#8220;Argument2&#8221; and so on...</p>
<p>Lets try to incorporate a for loop inside the fasta_counter.sh script that uses the first command line argument - i.e directory name and search for *.fna files in that directory and runs contig counting command on each of them.</p>
<ul class="simple">
<li>Open “fasta_counter.sh” in pico or your favourite text editor and follow instructions for making edits so it will do what we want it to do</li>
<li>Run this script in day1_morn directory and verify that you get the correct results. Basic usage of the script will be:</li>
</ul>
<p>./fasta_counter.sh <directory containing files></p>
<pre class="literal-block">
./fasta_counter.sh .
</pre>
<p>The &#8221;.&#8221; sign tells the script to use current directory as its first command line argument($1)</p>
</div>
<div class="section" id="power-of-unix-commands">
<span id="power-of-unix-commands"></span><h2>Power of Unix commands<a class="headerlink" href="#power-of-unix-commands" title="Permalink to this headline">¶</a></h2>
<p>In software carpentry, you learned working with shell and automating simple tasks using basic unix commands. Lets see how some of these commands can be employed in genomics analysis while exploring various file formats that we use in day to day analysis. For this session, we will try to explore three different types of bioinformatics file formats:</p>
<p>fasta: used for representing either nucleotide or peptide sequences</p>
<p>gff: used for describing genes and other features of DNA, RNA and protein sequences</p>
<p>fastq: used for storing biological sequence / sequencing reads (usually nucleotide sequence) and its corresponding quality scores</p>
<!--<ul class="simple">
<li>Question: Previously, you downloaded genome assembly fasta files and ran a shell script to count contigs. Now, lets say you want to find out the combined length of genome in each of these files. This can be achieved by running a short unix command piping together two unix programs: grep and wc. The key to crafting the command is understanding the  features of fasta files,</li>
</ul>
<blockquote>
<div><strong><em>1) each sequence in fasta file is preceded by a fasta header that starts with &#8220;&gt;&#8221;,</em></strong></div></blockquote>
<blockquote>
<div><strong><em>2) the types of bases that a nucleotide sequence represents (A,T,G,C,N)</em></strong></div></blockquote>
<p>To determine the total length of our genome assemblies, we will use grep to match only those lines that doesn&#8217;t start with &#8220;&gt;&#8221; (remember grep -v option is used to ignore lines). Then use wc command (stands for word count) to count the characters. We can use unix pipe &#8220;|&#8221; to pass the output of one command to another for further processing. Lets start by counting the number of bases in Acinetobacter_baumannii.fna file</p>
<p><details>
<summary>Solution</summary>
&#8211;&gt;</p>
<!--
grep -v '^>' Acinetobacter_baumannii.fna | sed 's/[N,n]//g' | awk -F '\n' '{sum += length} END {print sum}'
for i in *.fna; do grep -v '^>' $i | sed 's/[N,n]//g' | awk -F '\n' '{sum += length} END {print sum}'; done
grep -v '^#' sample.gff | awk -F '\t' '{print $3}' | grep 'rRNA' | wc -l
grep -v '^#' sample.gff | awk -F '\t' '{print $3}' | grep 'CDS' | wc -l
grep -v '^#' sample.gff | awk -F '\t' '{print $3}' | grep 'tRNA' | wc -l<pre class="literal-block">

grep -v '^&gt;' Acinetobacter_baumannii.fna | wc -m

#Note:

#- The sign &quot;^&quot; inside the grep pattern represents any pattern that starts with &quot;&gt;&quot; and -v asks grep to ignore those lines.
#- Use &quot;|&quot; to pass the output of one command to another.
#- -m parameter will show the character counts. Check wc help menu by typing &quot;wc --help&quot; on terminal to explore other parameters

</pre>
<p></details></p>
<p>Now run the same command on other fasta files in day1_morn directory. Try using a for loop.</p>
<p><details>
<summary>Solution</summary></p>
<pre class="literal-block">

for i in *.fna; do grep -v '^&gt;' $i | wc -m; done

</pre>
<p></details></p>
<p>&#8211;&gt;</p>
<p><strong>Unix one-liners</strong></p>
<p>As soon as you receive your sample data from sequencing centre, the first thing you do is check its quality using a quality control tool such as FastQC and make sure that it contain sequences from organism that you are working on (Free from any contamination). But before carrying out extensive QC, you can run a bash &#8220;one-liner&#8221; to get some basic statistics about the raw reads. These one-liners are great examples for how a set of simple (relatively) Unix commands can be piped together to do really useful things.</p>
<p>One such unix utility is Awk commands. Awk is a powerful unix utility that can be used to write tiny but effective programs in the form of statements that define text patterns that are to be searched for in each line of a file and the action that is to be taken when a match is found within a line. It is mostly used for pattern scanning and processing. It searches one or more files to see if they contain lines that matches with the specified patterns and then performs the associated actions.</p>
<p>A simple awk syntax is divided into three parts:</p>
<pre class="literal-block">
awk ' condition { action }'
</pre>
<p>If the line that awk reads satisfies the condition, it runs the action on it.</p>
<pre class="literal-block">

for i in Rush_KPC_266_*.gz; do zcat $i | awk 'BEGIN{OFS=&quot;\t&quot;};((NR-2)%4==0){read=$1;total++;len+=length(read)};END{print total,len/total}'; done

#The above awk command reads every fourth record and calculates some basic fastq statistics.

</pre>
<p>The above awk command reads every fourth record and calculates the number of reads and average read length.</p>
<p>Now try running above command using fastq_screen.fastq.gz as input.</p>
<p>To see the true power of Awk unix proggraming and understand how you can employ it to extract complex information, take a look at below command.</p>
<p>The following command will print total number of reads in each file, total number of unique reads, percentage of unique reads, most abundant sequence(useful to find adapter sequences or contamination), its frequency, and frequency of that sequence as a proportion of the total reads, average read length.</p>
<pre class="literal-block">

for i in Rush_KPC_266_*.gz; do zcat $i | awk 'BEGIN{OFS=&quot;\t&quot;};((NR-2)%4==0){read=$1;total++;count[read]++;len+=length(read)}END{for(read in count){if(!max||count[read]&gt;max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total,len/total}'; done

</pre>
<p>This command will parse a fastq file and calculate different statistics on the fly in a time efficient manner. Awk lets you perform and explore complex data files without the need for using a programming language or an individual tool.</p>
<p>You can find more of such super useful bash one-liners at Stephen Turner&#8217;s github <a class="reference external" href="https://github.com/stephenturner/oneliners">page</a>. You can also use some pre-written unix utilities and tools such as <a class="reference external" href="https://github.com/lh3/seqtk">seqtk</a>, <a class="reference external" href="https://github.com/lh3/bioawk">bioawk</a> and <a class="reference external" href="http://hannonlab.cshl.edu/fastx_toolkit/">fastx</a> which comes in handy while extracting complex information from fasta/fastq/sam/bam files and are optimized to be insanely fast.</p>
</div>
<div class="section" id="pairing-fastq-files-with-for-loop">
<span id="pairing-fastq-files-with-for-loop"></span><h2>Pairing fastq Files with for loop<a class="headerlink" href="#pairing-fastq-files-with-for-loop" title="Permalink to this headline">¶</a></h2>
<p>Oftentimes, bioinformatics analyses involves pairing a bunch of files that can then be used as an input for a command or a tool. The most common type of file that are used as pairs is fastq forward and reverse reads. In this exercise, we will go through a simple shell script that searches fastq files having a particular extension and generate a filename string for reverse paired end file.</p>
<p>The script fastq_pair.sh takes a path to directory as a command line argument and searches files with extension *_1_combine.fastq.gz and generates a filename with an extension *_2_combine.fastq.gz in it.</p>
<p>You can change the parameter suffix inside the script to look for a different entension.</p>
<pre class="literal-block">
less fastq_pair.sh 
</pre>
<p>Try running the script in the following fashion where . represents current directory:</p>
<pre class="literal-block">
./fastq_pair.sh .
</pre>
<p>How about running the awk command that we recently used inside a shell script and ask awk to print some statistics for both forward and reverse reads? Follow instructions in the script and Insert Awk command  in such a way that you use fwd_fastq_file and rev_fastq_file string accordingly.</p>
</div>
<div class="section" id="exploring-gff-files">
<span id="exploring-gff-files"></span><h2>Exploring GFF files<a class="headerlink" href="#exploring-gff-files" title="Permalink to this headline">¶</a></h2>
<p>The GFF (General Feature Format) format is a tab-seperated file and consists of one line per feature, each containing 9 columns of data.</p>
<p>column 1: seqname - name of the genome or contig or scaffold</p>
<p>column 2: source - name of the program that generated this feature, or the data source (database or project name)</p>
<p>column 3: feature - feature type name, e.g. Gene, exon, CDS, rRNA, tRNA, CRISPR, etc.</p>
<p>column 4: start - Start position of the feature, with sequence numbering starting at 1.</p>
<p>column 5: end - End position of the feature, with sequence numbering starting at 1.</p>
<p>column 6: score - A floating point value.</p>
<p>column 7: strand - defined as + (forward) or - (reverse).</p>
<p>column 8: frame - One of &#8216;0&#8217;, &#8216;1&#8217; or &#8216;2&#8217;. &#8216;0&#8217; indicates that the first base of the feature is the first base of a codon, &#8216;1&#8217; that the second base is the first base of a codon, and so on..</p>
<p>column 9: attribute - A semicolon-separated list of tag-value pairs, providing additional information about each feature such as gene name, product name etc.</p>
<ul class="simple">
<li>Use less to explore first few lines of a gff file sample.gff</li>
</ul>
<pre class="literal-block">

less sample.gff

</pre>
<p>Note: lines starting with pound sign &#8220;#&#8221; represent comments and are used to document extra information about the features.</p>
<p>You will notice that the GFF format follows version 3 specifications(&#8220;##gff-version 3&#8221;), followed by genome name(&#8220;#Genome: 1087440.3|Klebsiella pneumoniae subsp. pneumoniae KPNIH1&#8221;), date(&#8220;#Date:02/09/2017&#8221;) when it was generated, contig name(&#8220;##sequence-region&#8221;) and finally tab-seperated lines describing features.</p>
<p>You can press space bar on keyboard to read more lines and &#8220;q&#8221; key to exit less command.</p>
<ul class="simple">
<li>Question: Suppose, you want to find out the number of annotated features in a gff file. how will you achieve this using grep and wc?</li>
</ul>
<p><details>
<summary>Solution</summary></p>
<pre class="literal-block">
grep -v '^#' sample.gff | wc -l
</pre>
<p></details></p>
<ul class="simple">
<li>Question: How about counting the number of rRNA features in a gff(third column) file using grep, cut and wc? You can check the usage for cut by typing &#8220;cut &#8211;help&#8221;</li>
</ul>
<p><details>
<summary>Solution</summary></p>
<pre class="literal-block">

cut -f 3 sample.gff | grep 'rRNA' | wc -l

#Or number of CDS or tRNA features?

cut -f 3 sample.gff | grep 'CDS' | wc -l
cut -f 3 sample.gff | grep 'tRNA' | wc -l

#Note: In the above command, we are trying to extract feature information from third column.

</pre>
<p></details></p>
<ul class="simple">
<li>Question: Try counting the number of features on a &#8220;+&#8221; or &#8220;-&#8221; strand (column 7).</li>
</ul>
<p>Some more useful one-line unix commands for GFF files: <a class="reference external" href="https://github.com/stephenturner/oneliners#gff3-annotations">here</a></p>
<p>Now we&#8217;re going to play around with the GFF in R. Specifically, we&#8217;re interested in looking at the distribution of gene length for all of the genes in the gff file.</p>
<p>Copy the sample.gff file to your computer using scp or cyberduck:</p>
<pre class="literal-block">
scp username&#64;flux-xfer.arc-ts.umich.edu:/nfs/esnitkin/micro612w19_fluxod/shared/data/day1_morn/sample.gff ~/Desktop/
Note: You can use your choice of folder/path to copy the file instead of  “~/Desktop/”
</pre>
<p>Open a text file in RStudio and run the following commands:</p>
<pre class="literal-block">
# Plot histogram of gene lengths

# Read in gff file
gff = read.delim('~/Desktop/sample.gff',
                 comment.char = '#', # ignore lines that start with '#'
                 header=F) #  no header

# Rename columns
colnames(gff) = c('seqname','source','feature','start','end','score','strand','frame','attribute')

# Look at the head of the gff file
head(gff)

# Get the gene lengths
gene_lengths = gff$end - gff$start

# Plot a histogram of the gene lengths
hist(gene_lengths,
     breaks = 100, # 100 cells
     xlab = 'Gene Length (bp)', # change x label
     main = '') # no title
</pre>
<p>What information do you learn about gene lengths in this genome?</p>
</div>
<div class="section" id="plotting-genomic-coverage-in-r">
<span id="plotting-genomic-coverage-in-r"></span><h2>Plotting genomic coverage in R<a class="headerlink" href="#plotting-genomic-coverage-in-r" title="Permalink to this headline">¶</a></h2>
<p>Data visualization plays an important role in organizing, analyzing and interpreting large amount of omics data. R is one of the most basic and powerful tool for manipulating and visualizing these types of data. The following task will brush up some basic R plotting commands and help you visualize some complex omics data for interpretation.</p>
<p>One of the most common types of genomic analysis involves comparing the newly sequenced read data of an organism to your choice of reference organism genome. Mapping millions of reads generated in a sequencing experiment to the reference genome fasta file and interpreting various parameters can achieve this analysis.
One such parameter is validating how well your sequencing experiment performed and assessing the “uniformity” of coverage from whole-genome sequencing.&nbsp;Visualizing Sequencing coverage across the reference genome help us answer this question. Sequencing coverage describes the average number of reads that align to, or &#8220;cover,&#8221; known reference bases.</p>
<p>The input for this task is a comma-separated file, which contains average sequencing coverage information i.e average number of reads mapped to each 1000 base pairs in reference genome. You can find this input file in your day1_morn directory by the name, Ecoli_coverage_average_bed.csv</p>
<!---
Let’s copy Ecoli_coverage_average_bed.csv file from flux shared directory to your desktop using ‘
’. ‘
’ stands for secure copy and is used for securely transferring files between remote host/server(flux) and your local computer system. (Both directions)
scp username@flux-xfer.arc-ts.umich.edu:/scratch/micro612w19_fluxod/shared/Ecoli_coverage_average_bed.csv ~/Desktop/
Note: You can use your choice of folder/path to copy the file instead of  “~/Desktop/”
--><p>Drag and drop this Ecoli_coverage_average_bed.csv to your local system using cyberduck.</p>
<p>Now, Fire up R console or studio and import the file (Ecoli_coverage_average_bed.csv) using any type of data import functions in R (read.table, read.csv etc.)</p>
<p>Hint: The file is comma-separated and contains header line (“bin,Average_coverage”) so use appropriate parameters while importing the file</p>
<p>Once the data in file is imported into R object, you can plot the column Average_coverage as a time series plot to assess the coverage of your mapped reads across genome.</p>
<p>Note: A&nbsp;time series plot&nbsp;is a graph that you can use to evaluate patterns and behavior in data over&nbsp;time. Here, we can employ the same plot to see the pattern i.e read depth/coverage at each 1000 bases (represented by bins columns where each bin represents Average number of reads mapped to each 1000 bases in reference genome) using the simplest R function for time series such as <a class="reference external" href="http://stat.ethz.ch/R-manual/R-devel/library/stats/html/plot.ts.html">plot.ts</a></p>
<p>An example plot.ts plot for Ecoli_coverage_average_bed.csv is shown below for your reference.</p>
<p><img alt="alt tag" src="_images/plot_1.png" /></p>
<p>For advance and more beautiful visualization, ggplot2 can be employed to display the same plot. An example ggplot2 plot for Ecoli_coverage_average_bed.csv is shown below for your reference.</p>
<p><img alt="alt tag" src="_images/plot_2.png" /></p>
<p><details>
<summary>Solution</summary></p>
<pre class="literal-block">

x &lt;- read.table(&quot;Ecoli_coverage_average_bed.csv&quot;, sep=&quot;,&quot;, header=TRUE)
plot.ts(x$Average_coverage, xlab=&quot;Genome Position(1000bp bins)&quot;, ylab=&quot;Average Read Depth&quot;, main=&quot;Ecoli Bed Coverage&quot;, col=&quot;blue&quot;)

</pre>
<p></details></p>
</div>
<div class="section" id="submit-variant-calling-job">
<span id="submit-variant-calling-job"></span><h2>Submit Variant Calling Job<a class="headerlink" href="#submit-variant-calling-job" title="Permalink to this headline">¶</a></h2>
<p>Before we go on a break, we will run a variant calling job that will run all the standard variant calling commands on a sample that we will explore in today&#8217;s afternoon session. The script will run all necessary commands associated with variant calling in an automated fashion. This will let us give ample time to explore the commands that are involved in each of the steps and explore the results that the script generates.</p>
<p>We will come back later to the script to understand some of the basics of shell scripting and how different commands can be tied together to run a standard process on a bunch of samples.</p>
<ul class="simple">
<li>Go to your class home directory (use your wd shortcut!)</li>
<li>Execute the following commands to copy files for this afternoon’s exercises to your home directory:</li>
</ul>
<pre class="literal-block">

cp -r /scratch/micro612w19_fluxod/shared/data/day1_after/ ./

</pre>
<p>We will be using sequencing reads from an Illumina-sequenced <em>Klebsiella pneumoniae</em> genome (sample PCMP_H326) as an input for these exercises. This sample, isolated from a hospitalized patient, is resistant to colistin, an antibiotic of last resort. We are interested in seeing if we can identify any mutations in the PCMP_H326 genome that could explain why this sample is resistant to colistin. Colistin resistance can arise through various mutations (see <a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fmicb.2014.00643/full">this review</a>). To narrow our initial search, we will specifically look for mutations that inactivate the <a class="reference external" href="https://aac.asm.org/content/58/10/5696">mgrB gene</a>, a negative regulator of the PhoPQ two-component signalling system.</p>
<p>Change directory to day1_after and list all the files to search variant_call.sh script.</p>
<pre class="literal-block">
cd /scratch/micro612w19_fluxod/username/day1_after/

#or

d1a

ls variant_call.sh
</pre>
<p>Try running the script with help menu and check all the inputs that is required by the script to run variant calling.</p>
<pre class="literal-block">

./variant_call.sh -h

</pre>
<p>USAGE:
variant_call.sh forward_paired reverse_paired reference_genome output_directory basename [-h] &#8211; A simple shell script to run Variant Calling steps on a pair of fastq reads.</p>
<p>The script requires following positional arguments as input to call variants:</p>
<ol class="simple">
<li>Forward Paired end reads</li>
<li>Reverse Paired end reads</li>
<li>Path to Reference Genome Fasta file</li>
<li>Output Directory Path</li>
<li>Analysis Base name to store result files with this prefix.</li>
</ol>
<p>The day1_after directory also contains a pbs script that will run variant_call.sh on flux cluster. Edit this pbs script to customize email address and output directory to reflect your username specific paths.</p>
<p>Change the EMAIL_ADDRESS section of the pbs script to your email_address.</p>
<p>Change the output directory path in these line to reflect your output path which should be your day1_after directory. Also remember to change the path of reference genome to your day1_after directory. You can find this line at the end of the PBS script.</p>
<pre class="literal-block">

./variant_call.sh PCMP_H326_R1.fastq.gz PCMP_H326_R2.fastq.gz /Path-to-your-day1_after/KPNIH1.fasta /Path-to-your-day1_after/ PCMP_H326_

</pre>
<p>Once you are done editing the pbs script, you can go ahead and submit the job. We will go through each of the variant calling result steps folder and explore the results in afternoon session.</p>
<pre class="literal-block">

qsub variant_call.pbs 

</pre>
<p><strong>Note:</strong> We will be switching from pbs to slurm sometime this year. Here are some useful links about the switch:</p>
<ul class="simple">
<li>Tutorial:
https://www-personal.umich.edu/~mmiranda/BetaTutorial.pdf</li>
<li>Slides:
https://www-personal.umich.edu/~mmiranda/BetaSlides1811.pdf</li>
<li>Beta user guide:
https://arc-ts.umich.edu/beta/user-guide/</li>
<li>From Torque to Slurm:
http://arc-ts.umich.edu/migrating-from-torque-to-slurm/</li>
</ul>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="day1_afternoon.html" class="btn btn-neutral float-right" title="Day 1 Afternoon">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Microbial Comparative Genomics Workshop"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Evan Snitkin, Ali Pirani.
    </p>
  </div>

  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'3.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>